# AI-Based Early Fraud Detection for Sustainable Growth Metrics (MRR, CAC, LTV)

**Course:** Economics (Term Paper)
**Group:** GROUP 27

### Team Members

* **Shashank Patil (IIT2022226)**
* **Milan Bhatiya (IIT2022176)**
* **Rajat (IIT2022227)**

---

## ðŸ“Œ Project Overview

This project builds an **AI-powered early fraud detection framework** focused on identifying fraudulent users within the *first 30 days of acquisition*. Early-stage fraud distorts key business metrics used for growth planning and valuation.

By detecting fraud early, the system protects and stabilizes:

* **MRR** â€” avoids inflated recurring revenue from fake accounts
* **CAC** â€” reduces wasted marketing spend on fraudulent leads
* **LTV** â€” prevents artificial inflation by removing synthetic churners

This repository contains a **from-scratch ML & DL pipeline** (no scikitâ€‘learn) using:

* PyTorch
* NumPy
* Pandas
* NetworkX
* Matplotlib

---

## ðŸŽ¯ Aims & Objectives

### **Primary Aim**

Develop a system to detect fraud in the first 30 days and protect financial metrics.

### **Research Objective**

Evaluate a **multiâ€‘model AI ensemble**:

* Graph Neural Network (GNN)
* Random Forest (custom NumPy implementation)
* Isolation Forest (custom NumPy implementation)
* WGANâ€‘GP for synthetic fraud generation

### **Economic Objective**

Simulate impact on business KPIs:

* Target **15â€“25% improvement** in CACâ€‘toâ€‘LTV ratio
* Projected **>680% ROI** from reduced fraud losses

---

## ðŸ§  AI Methodology

This project is **AIâ€‘based**, not ruleâ€‘based. It learns patterns from data using a layered modeling approach.

| Component                  | Type              | Purpose                                                  |
| -------------------------- | ----------------- | -------------------------------------------------------- |
| **GNN**                    | Deep Learning     | Learns graphâ€‘based fraud patterns (transaction networks) |
| **Random Forest**          | ML Ensemble       | Tabular pattern learning via scratchâ€‘built tree ensemble |
| **Isolation Forest**       | Anomaly Detection | Finds unusual points without labels                      |
| **WGANâ€‘GP**                | Generative AI     | Creates synthetic fraud samples to fix data imbalance    |
| **Ensemble (2â€‘ofâ€‘3 vote)** | Metaâ€‘model        | Robust final fraud decision                              |

---

## ðŸ“‚ Dataset

**Dataset:** ULB Credit Card Fraud Dataset
**Rows:** 284,807 transactions
**Fraud cases:** 492 (0.172%) â€” extremely imbalanced

Why this dataset?

* Industryâ€‘standard benchmark
* Realistic anonymized PCA features
* Extreme imbalance â†’ ideal for GAN and anomalyâ€‘based models

---

## ðŸš€ How to Run

```bash
git clone <repo-url>
cd eco

python3 -m venv .venv
source .venv/bin/activate

pip install torch numpy pandas networkx matplotlib scipy
```

Download `creditcard.csv` into `data/raw/`

```bash
mkdir -p figures tables data/processed data/synthetic
python3 main.py
```

Outputs:

* **figures/** â†’ plots
* **tables/** â†’ performance tables

---

## ðŸ“Š Current Results (as of Nov 05, 2025)

### Table 1 â€” Model Performance

| Model            | Accuracy | Precision | Recall | F1    |
| ---------------- | -------- | --------- | ------ | ----- |
| GNN              | 0.99827  | 0.0       | 0.0    | 0.0   |
| Random Forest    | 0.99827  | 0.0       | 0.0    | 0.0   |
| Isolation Forest | 0.99737  | 0.239     | 0.239  | 0.239 |
| **Ensemble**     | 0.99827  | 0.0       | 0.0    | 0.0   |

**Insight:** High accuracy but **0 recall â†’ models predict "not fraud" always**

> Accuracy is meaningless in imbalanced problems

### Table 2 â€” Economic Simulation

| Scenario         | CAC | LTV | CAC/LTV |
| ---------------- | --- | --- | ------- |
| Before Detection | 120 | 300 | 0.4     |
| After Detection  | 120 | 300 | 0.4     |

**Why no change?**
Ensemble caught **0 fraud â†’ correct output** until recall improves

---

## ðŸ” Key Insights

* Accuracy â‰  quality in imbalanced datasets
* Isolation Forest shows promise â†’ detects anomalies
* GNN & RF need balancing + classâ€‘weighted loss

---

## ðŸ› ï¸ Next Steps (Fix Plan)

âœ… Use **WGANâ€‘GP synthetic samples** in training
âœ… **Classâ€‘weighted loss** for GNN

```python
criterion = nn.NLLLoss(weight=torch.FloatTensor([1.0, 578.0]))
```

âœ… Improve anomaly threshold tuning for IF
âœ… Retrain ensemble & evaluate economic impact

Expected outcome:

* Increase **recall > 0.5**
* Positive CAC/LTV improvement
* Realistic economic simulation

---

## ðŸ§¾ Conclusion

This project demonstrates:

* A realâ€‘world financial fraud challenge
* Deep learning + anomaly detection pipeline
* Fromâ€‘scratch ML implementation

Upcoming improvements will unlock:

* Higher fraud recall
* Proven positive business impact
* Strong economic insights for fintech & growth metrics

---

### ðŸ“Ž End of README
